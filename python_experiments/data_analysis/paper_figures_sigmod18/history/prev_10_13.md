## Evaluation Design 

### Scalability

speedup given varying number of threads (on CPU and KNL), 

```python
[1.0, 1.9006369042055722, 3.791854659915795, 7.614831712815106, 15.288058058886671, 30.615127288142965, 60.93945475198788, 88.13585085742896, 105.22759709327306]
[1.0, 1.8986820492171985, 3.760993083416151, 7.571861054787177, 15.24106164818907, 30.51158458997753, 60.4474480272897, 90.65075126282939, 106.71196454948303]
[1.0, 1.759967957022962, 3.534106120801833, 7.046549225731709, 14.014372765831343, 27.74660799413275, 53.173621554765354, 57.73926712757353, 55.21541784640532]

[1.0, 2.042952866248253, 4.139290835990481, 7.704681666602782, 15.351813890967968, 26.107032272812283, 43.288848688461044]
[1.0, 1.7824865383807005, 3.3790635711999752, 6.435343044503137, 11.795386023473673, 20.410452685759537, 32.639544122759105]
[1.0, 1.772919489110428, 3.4204541767460643, 6.251401801421897, 12.7833708349614, 16.44171215665887, 20.15484131367634]
```

### Comparison of Algorithms

**Two Big Figures**: 
12 (`5+4+3`) algorithms on real-world four datasets, 
12 algorithms on synthetic several datasets

All our algorithms with optimization techniques. 

* symmetric assignment (workload reduction), compared to SCAN-XP
* degree skewness (both real-world / synthetic)
* our two algorithms on three processors (strength and weakness)

category | configuration
--- | ---
real-world graphs | webbase (WB), web-it (WI), twitter (TW), friendster (FR)  
synthetic billion-edge graphs (by change from real-world graphs) | with max-degree: 0.1m, 1m, 10m, 100m  

platform | studied executable names 
--- | ---
KNL | SCAN-XP, Merge, Pivot, Hybrid, Bitmap2D
CPU | Merge, Pivot, Hybrid, Bitmap2D
mGPU | HybridWarp, HybridKernel, Bitmap2D

Attention: `mGPU` for multi-GPU. `SCAN-XP` and `Merge` 
are introduced for comparison of degree-skewness.

### Effectiveness of Task Parallelization

fix the twitter dataset as an example

**Four Figures**: 
scalability to number of threads on CPU, scalability to number of threads on KNL, 
scalability to number of GPUs on multi-GPU (compare dynamic load balance vs static load balance)

### Effectiveness of Hardware-Related Optimization

varying real-world datasets ï¼ˆfour datasets)

**Four Figures**: 

1) Bitmap1D vs Bitmap2D: Bitmap, Bitmap2D on both CPU and KNL 
2) MCDRAM-allocation-enabled vs not-hbw: Merge, Pivot, Hybrid, Bitmap2D
3) co-processing time: CPU co-processing time vs total elapsed time
4) vectoriztaion on our **hybrid method**: (AVX2, AVX512, naive-CPU, naive-KNL)